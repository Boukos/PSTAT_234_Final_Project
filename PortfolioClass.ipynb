{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTAT 234 Final Project - Portfolio Optimization\n",
    "\n",
    "### Presentation Time: Wed June 6, 11 - 12:15 pm\n",
    "\n",
    "### Group Member:\n",
    " - Xining Li\n",
    " - Ben Ku\n",
    " - Mi Yu\n",
    " - Zhipu Zhou\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import cvxpy as cvx\n",
    "from sklearn.model_selection import KFold # import KFold to do cross validation\n",
    "from sklearn.covariance import GraphLasso, GraphLassoCV, graph_lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy import linalg\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = np.arange(0, 0.5, 0.05)\n",
    "pr_all  =pd.DataFrame({'fold1':np.zeros(len(alpha)),'fold2':np.zeros(len(alpha)),\n",
    "                          'fold3':np.zeros(len(alpha)),'fold4':np.zeros(len(alpha)),\n",
    "                           'fold5':np.zeros(len(alpha))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fold1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str('fold'+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fold2': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fold3': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fold4': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fold5': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_fold=5\n",
    "default_data ={'fold1':np.zeros(len(alpha))}\n",
    "\n",
    "for ticker in range(n_fold):\n",
    "    default_data.update({str('fold'+str(ticker+1)): np.zeros(len(alpha))})\n",
    "default_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold1': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'fold2': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_data.update({'fold2': np.zeros(len(alpha))})\n",
    "default_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'fold1':np.zeros(len(alpha)),'fold2':np.zeros(len(alpha)),\n",
    "                          'fold3':np.zeros(len(alpha)),'fold4':np.zeros(len(alpha)),\n",
    "                           'fold5':np.zeros(len(alpha))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "      <th>fold3</th>\n",
       "      <th>fold4</th>\n",
       "      <th>fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold1  fold2  fold3  fold4  fold5\n",
       "0    0.0    0.0    0.0    0.0    0.0\n",
       "1    0.0    0.0    0.0    0.0    0.0\n",
       "2    0.0    0.0    0.0    0.0    0.0\n",
       "3    0.0    0.0    0.0    0.0    0.0\n",
       "4    0.0    0.0    0.0    0.0    0.0\n",
       "5    0.0    0.0    0.0    0.0    0.0\n",
       "6    0.0    0.0    0.0    0.0    0.0\n",
       "7    0.0    0.0    0.0    0.0    0.0\n",
       "8    0.0    0.0    0.0    0.0    0.0\n",
       "9    0.0    0.0    0.0    0.0    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# //                            _ooOoo_  \n",
    "# //                           o8888888o  \n",
    "# //                           88\" . \"88  \n",
    "# //                           (| -_- |)  \n",
    "# //                            O\\ = /O  \n",
    "# //                        ____/`---'\\____  \n",
    "# //                      .   ' \\\\| |// `.  \n",
    "# //                       / \\\\||| : |||// \\  \n",
    "# //                     / _||||| -:- |||||- \\  \n",
    "# //                       | | \\\\\\ - /// | |  \n",
    "# //                     | \\_| ''\\---/'' | |  \n",
    "# //                      \\ .-\\__ `-` ___/-. /  \n",
    "# //                   ___`. .' /--.--\\ `. . __  \n",
    "# //                .\"\" '< `.___\\_<|>_/___.' >'\"\".  \n",
    "# //               | | : `- \\`.;`\\ _ /`;.`/ - ` : | |  \n",
    "# //                 \\ \\ `-. \\_ __\\ /__ _/ .-` / /  \n",
    "# //         ======`-.____`-.___\\_____/___.-`____.-'======  \n",
    "# //                            `=---='  \n",
    "# //  \n",
    "# //         .............................................  \n",
    "# //                  佛祖保佑             永无BUG \n",
    "# //          佛曰:  \n",
    "# //                  写字楼里写字间，写字间里程序员；  \n",
    "# //                  程序人员写程序，又拿程序换酒钱。  \n",
    "# //                  酒醒只在网上坐，酒醉还来网下眠；  \n",
    "# //                  酒醉酒醒日复日，网上网下年复年。  \n",
    "# //                  但愿老死电脑间，不愿鞠躬老板前；  \n",
    "# //                  奔驰宝马贵者趣，公交自行程序员。  \n",
    "# //                  别人笑我忒疯癫，我笑自己命太贱；  \n",
    "# //                  不见满街漂亮妹，哪个归得程序员？\n",
    "\n",
    "# by applying Ledoit_wolf_cv the n_fold and shrinkage_num must be specified\n",
    "class portfolio_optimization():\n",
    "    \"\"\"This is a portfolio optimization class aiming to the Realized Return, \n",
    "    shortsize, turnover, and ending portfolio value. \n",
    "    \n",
    "    Input, stock data address, selected companies name, days of period\n",
    "    Using lediot_wolf, must specify n_fold and shrinkage_num\n",
    "    Using graphical_lasso, must specify n_fold and \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 stock_dat_address, \n",
    "                 selected_companies_names ,\n",
    "                 days_of_period,\n",
    "                 start, \n",
    "                 covariance_method,\n",
    "                 **method_parameters):\n",
    "        self.selected_companies_names = selected_companies_names\n",
    "        self.stock_data = pd.read_pickle(stock_dat_address).dropna(axis = 1)[selected_companies_names]\n",
    "        self.days_of_period =days_of_period\n",
    "        self.covariance_method = covariance_method\n",
    "        self.start = start\n",
    "        \n",
    "        if covariance_method!='sample':\n",
    "            \n",
    "            for key, value in method_parameters.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    ## The optimal_solution not considering the period\n",
    "     \n",
    "        self.Mat_Optimization_At_Each_Period = self.Optimization_At_Each_Period()  \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ##This is a Lediot_wolf method's function used to do cross-validation \n",
    "    # and compare the predictive risk\n",
    "    ##There might be a problem, but I cannot find it because the difference\n",
    "    ##in the predictive risk seems to be pretty random. We might not use this to do\n",
    "    ##cross-validation\n",
    "\n",
    "\n",
    "    #input the data, the number of folds, and the number of shrinkages value we want to test\n",
    "    def Ledoit_wolf_cv(self, data,n_fold,shrinkage_num):\n",
    "        #The space between each fold\n",
    "        z = 1.0/shrinkage_num\n",
    "        shrinkage = np.arange(0,1,z)\n",
    "        #create a dictionary with lambda as keys and their predictive risk as values\n",
    "        #set the initial predictive risk to be 1\n",
    "        shrinkage_dict = dict((el,0) for el in shrinkage)\n",
    "        #loop through all the possible shrinkage values\n",
    "        for l in shrinkage:\n",
    "            #split into n-fold\n",
    "            kf = KFold(n_splits = n_fold)\n",
    "            #initialize the predictive risk\n",
    "            pr_total = 0\n",
    "            for train, test in kf.split(data):\n",
    "                 #get the training set\n",
    "                X_train = data.iloc[train]\n",
    "                #calculate the sample covariance matrix\n",
    "                sample = np.cov(X_train,rowvar = False)\n",
    "                ##next get the Ledoit-Wolf covariance matrix using the shriankgage \n",
    "                lw = np.multiply(sample,l) + np.multiply((1.0-l),np.identity(30))\n",
    "                ##calculate the omega matrix\n",
    "                omega = np.linalg.inv(lw)\n",
    "                ##calculate the predictive risk\n",
    "                ##Also first centralize the test data\n",
    "                X_test = data.iloc[test]\n",
    "                X_test_central = X_test.sub(X_test.mean(axis=0), axis=1)\n",
    "                X_test_central = np.asmatrix(X_test_central)\n",
    "                omega_diag = np.diag(np.diag(omega))\n",
    "                omega_diag_inv = np.linalg.inv(omega_diag)\n",
    "                #This calculates the quantity inside the norm\n",
    "                z = np.matmul(omega,omega_diag_inv)\n",
    "                m = np.matmul(X_test_central,z) \n",
    "                #calculate the predictive risk\n",
    "                pr = (np.linalg.norm(m,2))**2/len(test)\n",
    "                pr_total += pr\n",
    "            shrinkage_dict[l] = pr_total\n",
    "        #This gives the best shrinkage value after the cross-validation\n",
    "        best_shrinkage = min(shrinkage_dict, key=shrinkage_dict.get) \n",
    "        actual_sample = np.cov(data,rowvar = False)\n",
    "        ##Using the best shrinkage to get the Ledoit-Wolf covariance matrix\n",
    "        return np.multiply(actual_sample,best_shrinkage) + np.multiply((1.0-best_shrinkage),np.identity(30))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Graph Lasso Function\n",
    "    def graphlasso_cv(self, data,alpha_num,n_fold):\n",
    "        datac = pd.DataFrame(scale(data, axis = 0, with_mean = True, with_std = True, copy = True))\n",
    "        sdv = data.std(axis = 0)\n",
    "        alpha = np.arange(0, 0.5, 0.05)\n",
    "        \n",
    "        \n",
    "        n_fold=5\n",
    "        default_fold ={'fold1':np.zeros(len(alpha))}\n",
    "\n",
    "        for ticker in range(n_fold):\n",
    "            default_fold.update({str('fold'+str(ticker+1)): np.zeros(len(alpha))})\n",
    "        \n",
    "        pr_all  =pd.DataFrame(default_fold)\n",
    "        pr_all.index = alpha\n",
    "        for l in alpha:\n",
    "            #split into n-fold\n",
    "            print(l)\n",
    "            kf = KFold(n_splits = n_fold)\n",
    "            #initialize the predictive risk\n",
    "            ii = -1\n",
    "            for train, test in kf.split(datac):\n",
    "                ii = ii + 1\n",
    "                x_train = datac.iloc[train]\n",
    "                x_test = datac.iloc[test]\n",
    "                ##next get the Graph Lasso covariance matrix using the shriankgage \n",
    "                model = GraphLasso(l)\n",
    "                model.fit(x_train)\n",
    "                omega = model.precision_\n",
    "                ##calculate the predictive risk\n",
    "                omega_diag = np.diag(np.diag(omega))\n",
    "                omega_diag_inv = np.diag(1/np.diag(omega))\n",
    "                #This calculates the quantity inside the norm\n",
    "                z = np.matmul(omega,omega_diag_inv)\n",
    "                m = np.matmul(x_test,z) \n",
    "                #calculate the predictive risk\n",
    "                pr = (np.linalg.norm(m,2))**2/x_test.shape[0]\n",
    "                pr_all.loc[l][ii] = pr\n",
    "        #This gives the best alpha value after the cross-validation\n",
    "        best_alpha = np.argmin(pr_all.mean(axis = 1))\n",
    "        model = GraphLasso(best_alpha)\n",
    "        model.fit(datac)\n",
    "        omega = np.matmul(np.matmul(np.diag(sdv), model.precision_), np.diag(sdv))\n",
    "        return omega, best_alpha\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def optimal_solution(self, stock_data_partition, covariance_method = 'sample', inverse = False):\n",
    "        def mat_mults(*args):\n",
    "            if(len(args)==1):\n",
    "                return args[0]\n",
    "            else:\n",
    "                    return np.matmul(args[0],mat_mults(*args[1:]))\n",
    "        ########\n",
    "\n",
    "        \n",
    "        if (self.covariance_method == 'sample'):\n",
    "            logret = np.log(stock_data_partition).diff()\n",
    "            mu = logret[1:].mean()\n",
    "            sigma = logret.cov()\n",
    "            s, _ = sigma.shape\n",
    "            w = cvx.Variable(s)# the length of w is x\n",
    "            risk = cvx.quad_form(w, sigma.as_matrix())\n",
    "            prob = cvx.Problem(cvx.Minimize(risk),\n",
    "                               [cvx.sum_entries(w) == 1])\n",
    "            prob.solve()\n",
    "            return w.value\n",
    "        \n",
    "        \n",
    "        if (self.covariance_method == 'ledoit_wolf'):\n",
    "            sigma =  self.Ledoit_wolf_cv(stock_data_partition,self.n_fold,self.shrinkage_num)\n",
    "            ##Next let us calculate the weights\n",
    "            one_vec = np.asmatrix(np.ones(len(self.selected_companies_names)))\n",
    "            ##Based on the optimal solution formula\n",
    "            sigma_inv = np.linalg.inv(sigma)\n",
    "            one_tp = np.transpose(one_vec)\n",
    "            p = np.matmul(sigma_inv,one_tp)\n",
    "            q = (np.matmul(one_vec,np.matmul(sigma_inv,one_tp)))\n",
    "            weight = np.multiply(1.0/float(q),p)\n",
    "            return weight\n",
    "\n",
    "        if (self.covariance_method == 'graphical_lasso'):\n",
    "            sigma_inv, best_beta =  self.graphlasso_cv(stock_data_partition,self.alpha_num,self.n_fold)\n",
    "            ##Next let us calculate the weights\n",
    "            one_vec = np.asmatrix(np.ones(len(self.selected_companies_names)))\n",
    "            ##Based on the optimal solution formula\n",
    "            one_tp = np.transpose(one_vec)\n",
    "            p = np.matmul(sigma_inv,one_tp)\n",
    "            q = (np.matmul(one_vec,np.matmul(sigma_inv,one_tp)))\n",
    "            weight = np.multiply(1.0/float(q),p)\n",
    "            return weight\n",
    "\n",
    "\n",
    "\n",
    "    #### Postcondition: calculate all w ##############\n",
    "    def Optimization_At_Each_Period(self):\n",
    "        w=[]\n",
    "        for current_period_num in range(int(np.floor( (len(self.stock_data)/self.days_of_period) ))):\n",
    "             \n",
    "            stock_data_partition = self.stock_data[current_period_num*self.days_of_period:(current_period_num+1)*self.days_of_period].copy()\n",
    "            w.append(self.optimal_solution(stock_data_partition))\n",
    "        return np.column_stack(w)\n",
    "\n",
    "    \n",
    "    ################## Split all returns by chunk #####################\n",
    "    def return_over_time(self):\n",
    "        re=[]\n",
    "        for current_period_num in range(int(np.floor( (len(self.stock_data)/self.days_of_period) ))):\n",
    "            after = self.stock_data[(self.days_of_period*current_period_num+1):(self.days_of_period*(current_period_num+1)+1)]\n",
    "            before = self.stock_data[(self.days_of_period*current_period_num):(self.days_of_period*(current_period_num+1))]\n",
    "            tmp = np.log(np.array(after)/np.array(before))\n",
    "            tmp = pd.DataFrame(tmp,columns = after.columns)\n",
    "            re.append(tmp)\n",
    "\n",
    "        if len(self.stock_data)/self.days_of_period-int(len(self.stock_data)/self.days_of_period)==0:\n",
    "            return re\n",
    "        else:\n",
    "            # print (\"Last Trading Period Not Finished\")\n",
    "            last_start=int(np.floor( (len(self.stock_data)/self.days_of_period) ))*self.days_of_period\n",
    "            last_end=len(self.stock_data)-1\n",
    "            before = self.stock_data[(last_start-1):(last_end-1)]\n",
    "            after = self.stock_data[last_start:last_end]\n",
    "            tmp = np.log(np.array(after)/np.array(before))\n",
    "            tmp = pd.DataFrame(tmp,columns = after.columns)\n",
    "            re.append(tmp)\n",
    "            return re\n",
    "        ################## Generate interval for re-balancing ####################\n",
    "    def generate_interval(self):\n",
    "\n",
    "        n = self.days_of_period\n",
    "        starn = np.asscalar(np.where(self.stock_data.index == self.start)[0])\n",
    "\n",
    "        invs = pd.Series(np.arange(starn, self.stock_data.shape[0], n))\n",
    "        inve = pd.Series(np.arange(starn+n-1, self.stock_data.shape[0], n))\n",
    "        inve[len(inve)] = self.stock_data.shape[0]\n",
    "        este = invs - 1\n",
    "        ests = invs - n\n",
    "        interval = pd.DataFrame({'es':ests, 'ee':este, 'is':invs, 'ie':inve}).astype('int')\n",
    "        self.interval = interval\n",
    "        return interval\n",
    "\n",
    "    ################## Calculate daily return of a portfolio #################\n",
    "    def Realized_Return(self):\n",
    "\n",
    "        interval = self.generate_interval()\n",
    "\n",
    "        data = self.stock_data[interval.loc[0,'es']:interval.loc[interval.shape[0]-1,'ie']]\n",
    "        Mat_return_over_time = self.return_over_time()  # return dataframe by chunks\n",
    "        Total_time = self.Mat_Optimization_At_Each_Period.shape[1]  # Number of periods\n",
    "        ss = self.shortsize()  # Size of short side\n",
    "        daily_r = pd.DataFrame()\n",
    "        for t in range(Total_time):\n",
    "            tmp = pd.DataFrame(np.matmul(Mat_return_over_time[t + 1], self.Mat_Optimization_At_Each_Period[:,t]))\n",
    "            daily_r  = pd.concat([daily_r, tmp])\n",
    "            self.daily_r = daily_r\n",
    "        index_num = daily_r.shape[0]\n",
    "        daily_r.index =  list(self.stock_data.index)[-index_num:]\n",
    "        return daily_r\n",
    "\n",
    "    ################# Calculate short size for all periods #################\n",
    "    def shortsize(self):\n",
    "        ss = np.empty(self.Mat_Optimization_At_Each_Period.shape[1])  # take number of columns (number of periods)\n",
    "        upper = np.empty(self.Mat_Optimization_At_Each_Period.shape[1])\n",
    "        for i in range(self.Mat_Optimization_At_Each_Period.shape[1]):\n",
    "            absw = np.array([np.min(np.array([np.asscalar(j),0])) for j in self.Mat_Optimization_At_Each_Period[:,i]])\n",
    "            upper[i] = np.sum(np.abs(absw))\n",
    "            ss[i] = upper[i] / np.sum(np.abs(self.Mat_Optimization_At_Each_Period[:,i]))\n",
    "            self.upper = upper\n",
    "            self.ss=ss\n",
    "        return ss, upper\n",
    "\n",
    "    ################# Calculate turnover rate for all periods ###############\n",
    "    def turnover(self):\n",
    "        interval = self.generate_interval()  # Interval\n",
    "        Mat_return_over_time = self.return_over_time()  # return dataframe by chunks\n",
    "\n",
    "        TO = np.empty(interval.shape[0])\n",
    "        for i in range(interval.shape[0]):\n",
    "            if(i == 0):\n",
    "                wold = np.zeros(self.stock_data.shape[1])\n",
    "            else:\n",
    "                wold = np.array([j[0] for j in np.asarray(self.Mat_Optimization_At_Each_Period[:,i-1])])\n",
    "            wnew = np.array([j[0] for j in np.asarray(self.Mat_Optimization_At_Each_Period[:,i])])\n",
    "            TO[i] = np.sum(np.abs(wnew - np.multiply.accumulate(Mat_return_over_time[0] + 1, axis = 0).iloc[-1] * wold))\n",
    "        self.TO = TO\n",
    "        return TO\n",
    "\n",
    "    ################## Calculate daily wealth of a portfolio  ################\n",
    "    # borr_cost is daily rate\n",
    "    def Port_Wealth(self,\n",
    "                    trans_cost = 0, \n",
    "                    borr_cost = 0, \n",
    "                    init = 1):\n",
    "              \n",
    "        daily_r = self.Realized_Return()\n",
    "        TO = self.turnover()\n",
    "        ss, upper = self.shortsize()\n",
    "        interval = self.generate_interval()\n",
    "        \n",
    "        ptf_r = daily_r.copy()\n",
    "        invs = interval[\"is\"] - interval['is'][0]\n",
    "        n = interval['ee'][0] - interval['es'][0] + 1\n",
    "        for k in range(interval.shape[0]):\n",
    "            ptf_r.iloc[invs[k]] = ptf_r.iloc[invs[k]] - TO[k] * trans_cost - upper[k] * (math.pow(1 + borr_cost, n) - 1)\n",
    "        ptf_w = init * np.multiply.accumulate(ptf_r + 1)\n",
    "        index_num = ptf_w.shape[0]\n",
    "        ptf_w.index =  list(self.stock_data.index)[-index_num:]\n",
    "        return ptf_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DIS','D','XOM','GE','GS','HD','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT']\n",
    "\n",
    "po=portfolio_optimization(\"./closing_price_5yr.pkl\",ticket, 21,'2014-05-21',covariance_method='ledoit_wolf',n_fold=5,shrinkage_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-21</th>\n",
       "      <td>1.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-24</th>\n",
       "      <td>0.989848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "      <td>0.995587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-26</th>\n",
       "      <td>1.005827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-27</th>\n",
       "      <td>1.012256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-28</th>\n",
       "      <td>1.010559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>1.012335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>1.011369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>1.014293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>1.022712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-08</th>\n",
       "      <td>1.024424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-09</th>\n",
       "      <td>1.032464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10</th>\n",
       "      <td>1.032561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-11</th>\n",
       "      <td>1.048366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-12</th>\n",
       "      <td>1.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>1.047317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>1.045779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-17</th>\n",
       "      <td>1.044482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-18</th>\n",
       "      <td>1.042512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-19</th>\n",
       "      <td>1.036531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-22</th>\n",
       "      <td>1.039821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-23</th>\n",
       "      <td>1.036189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>1.037282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>1.039665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-26</th>\n",
       "      <td>1.042182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>1.041481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-30</th>\n",
       "      <td>1.042147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>1.034487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>1.042440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-02</th>\n",
       "      <td>1.045909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>1.725933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>1.747158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>1.740195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>1.751772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13</th>\n",
       "      <td>1.755177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>1.766554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>1.787390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>1.779549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>1.778779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>1.774626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>1.783890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>1.788790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>1.785281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>1.772723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>1.792320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>1.800020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>1.788663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>1.776696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>1.759460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>1.750006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>1.770179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>1.770005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1.765406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>1.772075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>1.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>1.798449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>1.798010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>1.793442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>1.802292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>1.795458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "2013-06-21  1.002078\n",
       "2013-06-24  0.989848\n",
       "2013-06-25  0.995587\n",
       "2013-06-26  1.005827\n",
       "2013-06-27  1.012256\n",
       "2013-06-28  1.010559\n",
       "2013-07-01  1.012335\n",
       "2013-07-02  1.011369\n",
       "2013-07-03  1.014293\n",
       "2013-07-05  1.022712\n",
       "2013-07-08  1.024424\n",
       "2013-07-09  1.032464\n",
       "2013-07-10  1.032561\n",
       "2013-07-11  1.048366\n",
       "2013-07-12  1.047800\n",
       "2013-07-15  1.047317\n",
       "2013-07-16  1.045779\n",
       "2013-07-17  1.044482\n",
       "2013-07-18  1.042512\n",
       "2013-07-19  1.036531\n",
       "2013-07-22  1.039821\n",
       "2013-07-23  1.036189\n",
       "2013-07-24  1.037282\n",
       "2013-07-25  1.039665\n",
       "2013-07-26  1.042182\n",
       "2013-07-29  1.041481\n",
       "2013-07-30  1.042147\n",
       "2013-07-31  1.034487\n",
       "2013-08-01  1.042440\n",
       "2013-08-02  1.045909\n",
       "...              ...\n",
       "2018-04-09  1.725933\n",
       "2018-04-10  1.747158\n",
       "2018-04-11  1.740195\n",
       "2018-04-12  1.751772\n",
       "2018-04-13  1.755177\n",
       "2018-04-16  1.766554\n",
       "2018-04-17  1.787390\n",
       "2018-04-18  1.779549\n",
       "2018-04-19  1.778779\n",
       "2018-04-20  1.774626\n",
       "2018-04-23  1.783890\n",
       "2018-04-24  1.788790\n",
       "2018-04-25  1.785281\n",
       "2018-04-26  1.772723\n",
       "2018-04-27  1.792320\n",
       "2018-04-30  1.800020\n",
       "2018-05-01  1.788663\n",
       "2018-05-02  1.776696\n",
       "2018-05-03  1.759460\n",
       "2018-05-04  1.750006\n",
       "2018-05-07  1.770179\n",
       "2018-05-08  1.770005\n",
       "2018-05-09  1.765406\n",
       "2018-05-10  1.772075\n",
       "2018-05-11  1.788314\n",
       "2018-05-14  1.798449\n",
       "2018-05-15  1.798010\n",
       "2018-05-16  1.793442\n",
       "2018-05-17  1.802292\n",
       "2018-05-18  1.795458\n",
       "\n",
       "[1237 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.Port_Wealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.560e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -2.599e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 2.333e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -4.325e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -2.067e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -2.477e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 2.047e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 4.676e-04\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -4.049e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -2.706e-04\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 9.805e-04\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 6.060e-04\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.35000000000000003\n",
      "0.4\n",
      "0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 4.465e-02\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -3.105e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 7.826e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 2.915e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -3.066e-02\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -1.407e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -4.441e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 9.712e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.765e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -3.530e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -5.672e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -5.326e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 5.890e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -6.103e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -6.417e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.897e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 2.394e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 3.287e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -3.634e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.282e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -4.606e-04\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -3.265e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.278e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -5.572e-04\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35000000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -1.947e-04\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.852e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.366e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.611e-03\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 1.765e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 8.041e-04\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 5.757e-04\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 4.529e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -2.608e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -1.628e-02\n",
      "  ConvergenceWarning)\n",
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: 2.629e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiningli/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py:252: ConvergenceWarning: graph_lasso: did not converge after 100 iteration: dual gap: -7.657e-03\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "Non SPD result: the system is too ill-conditioned for this solver. The system is too ill-conditioned for this solver",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0a5f87a0e5b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mticket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'MMM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AXP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CAT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CVX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CSCO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'KO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DIS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'XOM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'IBM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'INTC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JNJ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JPM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MCD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MRK'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MSFT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NKE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PFE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TRV'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'UTX'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'UNH'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'VZ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'WMT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpo2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mportfolio_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./closing_price_5yr.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mticket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2014-05-21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovariance_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'graphical_lasso'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b6240c7230b5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stock_dat_address, selected_companies_names, days_of_period, start, covariance_method, **method_parameters)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m## The optimal_solution not considering the period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMat_Optimization_At_Each_Period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimization_At_Each_Period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b6240c7230b5>\u001b[0m in \u001b[0;36mOptimization_At_Each_Period\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mstock_data_partition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_period_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_of_period\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_period_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays_of_period\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data_partition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b6240c7230b5>\u001b[0m in \u001b[0;36moptimal_solution\u001b[0;34m(self, stock_data_partition, covariance_method, inverse)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'graphical_lasso'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0msigma_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_beta\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphlasso_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data_partition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;31m##Next let us calculate the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mone_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_companies_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b6240c7230b5>\u001b[0m in \u001b[0;36mgraphlasso_cv\u001b[0;34m(self, data, alpha_num, n_fold)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m##next get the Graph Lasso covariance matrix using the shriankgage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0momega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m##calculate the predictive risk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0memp_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0menet_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menet_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             verbose=self.verbose, return_n_iter=True)\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py\u001b[0m in \u001b[0;36mgraph_lasso\u001b[0;34m(emp_cov, alpha, cov_init, mode, tol, enet_tol, max_iter, verbose, return_costs, eps, return_n_iter)\u001b[0m\n\u001b[1;32m    254\u001b[0m         e.args = (e.args[0]\n\u001b[1;32m    255\u001b[0m                   + '. The system is too ill-conditioned for this solver',)\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_costs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/covariance/graph_lasso_.py\u001b[0m in \u001b[0;36mgraph_lasso\u001b[0;34m(emp_cov, alpha, cov_init, mode, tol, enet_tol, max_iter, verbose, return_costs, eps, return_n_iter)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 raise FloatingPointError('Non SPD result: the system is '\n\u001b[0m\u001b[1;32m    248\u001b[0m                                          'too ill-conditioned for this solver')\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: Non SPD result: the system is too ill-conditioned for this solver. The system is too ill-conditioned for this solver"
     ]
    }
   ],
   "source": [
    "ticket = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DIS','D','XOM','GE','GS','HD','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT']\n",
    "\n",
    "po2=portfolio_optimization(\"./closing_price_5yr.pkl\",ticket, 21,'2014-05-21',covariance_method='graphical_lasso',alpha_num=100,n_fold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-21</th>\n",
       "      <td>1.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-24</th>\n",
       "      <td>0.989848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "      <td>0.995587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-26</th>\n",
       "      <td>1.005827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-27</th>\n",
       "      <td>1.012256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-28</th>\n",
       "      <td>1.010559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>1.012335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>1.011369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>1.014293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>1.022712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-08</th>\n",
       "      <td>1.024424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-09</th>\n",
       "      <td>1.032464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10</th>\n",
       "      <td>1.032561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-11</th>\n",
       "      <td>1.048366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-12</th>\n",
       "      <td>1.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>1.047317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>1.045779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-17</th>\n",
       "      <td>1.044482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-18</th>\n",
       "      <td>1.042512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-19</th>\n",
       "      <td>1.036531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-22</th>\n",
       "      <td>1.039821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-23</th>\n",
       "      <td>1.036189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>1.037282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>1.039665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-26</th>\n",
       "      <td>1.042182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>1.041481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-30</th>\n",
       "      <td>1.042147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>1.034487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>1.042440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-02</th>\n",
       "      <td>1.045909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>1.725933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>1.747158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>1.740195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>1.751772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13</th>\n",
       "      <td>1.755177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>1.766554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>1.787390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>1.779549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>1.778779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>1.774626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>1.783890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>1.788790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>1.785281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>1.772723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>1.792320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>1.800020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>1.788663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>1.776696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>1.759460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>1.750006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>1.770179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>1.770005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1.765406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>1.772075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>1.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>1.798449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>1.798010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>1.793442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>1.802292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>1.795458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "2013-06-21  1.002078\n",
       "2013-06-24  0.989848\n",
       "2013-06-25  0.995587\n",
       "2013-06-26  1.005827\n",
       "2013-06-27  1.012256\n",
       "2013-06-28  1.010559\n",
       "2013-07-01  1.012335\n",
       "2013-07-02  1.011369\n",
       "2013-07-03  1.014293\n",
       "2013-07-05  1.022712\n",
       "2013-07-08  1.024424\n",
       "2013-07-09  1.032464\n",
       "2013-07-10  1.032561\n",
       "2013-07-11  1.048366\n",
       "2013-07-12  1.047800\n",
       "2013-07-15  1.047317\n",
       "2013-07-16  1.045779\n",
       "2013-07-17  1.044482\n",
       "2013-07-18  1.042512\n",
       "2013-07-19  1.036531\n",
       "2013-07-22  1.039821\n",
       "2013-07-23  1.036189\n",
       "2013-07-24  1.037282\n",
       "2013-07-25  1.039665\n",
       "2013-07-26  1.042182\n",
       "2013-07-29  1.041481\n",
       "2013-07-30  1.042147\n",
       "2013-07-31  1.034487\n",
       "2013-08-01  1.042440\n",
       "2013-08-02  1.045909\n",
       "...              ...\n",
       "2018-04-09  1.725933\n",
       "2018-04-10  1.747158\n",
       "2018-04-11  1.740195\n",
       "2018-04-12  1.751772\n",
       "2018-04-13  1.755177\n",
       "2018-04-16  1.766554\n",
       "2018-04-17  1.787390\n",
       "2018-04-18  1.779549\n",
       "2018-04-19  1.778779\n",
       "2018-04-20  1.774626\n",
       "2018-04-23  1.783890\n",
       "2018-04-24  1.788790\n",
       "2018-04-25  1.785281\n",
       "2018-04-26  1.772723\n",
       "2018-04-27  1.792320\n",
       "2018-04-30  1.800020\n",
       "2018-05-01  1.788663\n",
       "2018-05-02  1.776696\n",
       "2018-05-03  1.759460\n",
       "2018-05-04  1.750006\n",
       "2018-05-07  1.770179\n",
       "2018-05-08  1.770005\n",
       "2018-05-09  1.765406\n",
       "2018-05-10  1.772075\n",
       "2018-05-11  1.788314\n",
       "2018-05-14  1.798449\n",
       "2018-05-15  1.798010\n",
       "2018-05-16  1.793442\n",
       "2018-05-17  1.802292\n",
       "2018-05-18  1.795458\n",
       "\n",
       "[1237 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.Port_Wealth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_value(n):\n",
    "    tmp = portfolio_optimization(\"./closing_price_5yr.pkl\",ticket, n,'2014-05-21')\n",
    "    if (n<tmp.stock_data.shape[1]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return tmp.Port_Wealth().iloc[-1:].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.9069856230798227, 1.4779937991942707, 1.2219045269130393]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(portfolio_value,[21,63,126,262]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.12175338, -0.15350017,  0.03202763, ..., -0.15119153,\n",
       "         -0.24572279, -0.63837422],\n",
       "        [-0.13092679,  0.13115644, -0.12896231, ..., -0.58849685,\n",
       "         -0.54366081, -0.1362559 ],\n",
       "        [ 0.48487168,  0.21159928,  0.02470386, ..., -0.08719473,\n",
       "         -0.4853602 , -0.25892601],\n",
       "        ...,\n",
       "        [ 0.10661925, -0.16541563,  0.04592203, ..., -0.14880982,\n",
       "          0.13409742, -0.24691324],\n",
       "        [-0.15956028, -0.47217194,  0.03172527, ...,  0.03218914,\n",
       "          0.23495587,  0.13058959],\n",
       "        [ 0.18916849,  0.06144344,  0.05197028, ..., -0.11184307,\n",
       "          0.32706739, -0.18653387]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.Mat_Optimization_At_Each_Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.portfolio_optimization at 0x7fdf1c955898>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.812886590655414"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.iloc[-1:].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-21</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-24</th>\n",
       "      <td>-0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-26</th>\n",
       "      <td>0.005182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-27</th>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-28</th>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>-0.007564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-08</th>\n",
       "      <td>0.011465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-09</th>\n",
       "      <td>-0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10</th>\n",
       "      <td>0.000656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-11</th>\n",
       "      <td>0.010266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-12</th>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>-0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-17</th>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-18</th>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-19</th>\n",
       "      <td>-0.003563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-22</th>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-23</th>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>-0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>0.010755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-26</th>\n",
       "      <td>-0.003715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>-0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-30</th>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>0.012699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-02</th>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>0.003369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>-0.001930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13</th>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>-0.003949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>-0.007580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>0.004979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>-0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>0.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>-0.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>-0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>-0.009396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>-0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>0.004395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>-0.005701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>0.009115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>-0.007251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>-0.001162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>-0.002042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "2013-06-21  0.000562\n",
       "2013-06-24 -0.009072\n",
       "2013-06-25  0.003396\n",
       "2013-06-26  0.005182\n",
       "2013-06-27  0.003667\n",
       "2013-06-28  0.004603\n",
       "2013-07-01  0.005177\n",
       "2013-07-02 -0.007564\n",
       "2013-07-03  0.001480\n",
       "2013-07-05  0.008006\n",
       "2013-07-08  0.011465\n",
       "2013-07-09 -0.000653\n",
       "2013-07-10  0.000656\n",
       "2013-07-11  0.010266\n",
       "2013-07-12  0.002726\n",
       "2013-07-15  0.003748\n",
       "2013-07-16 -0.002495\n",
       "2013-07-17  0.000382\n",
       "2013-07-18  0.002447\n",
       "2013-07-19 -0.003563\n",
       "2013-07-22  0.003528\n",
       "2013-07-23  0.004957\n",
       "2013-07-24 -0.005660\n",
       "2013-07-25  0.010755\n",
       "2013-07-26 -0.003715\n",
       "2013-07-29 -0.002933\n",
       "2013-07-30  0.000797\n",
       "2013-07-31  0.001045\n",
       "2013-08-01  0.012699\n",
       "2013-08-02  0.000925\n",
       "...              ...\n",
       "2018-04-09 -0.001053\n",
       "2018-04-10  0.003369\n",
       "2018-04-11 -0.000177\n",
       "2018-04-12 -0.001930\n",
       "2018-04-13 -0.000146\n",
       "2018-04-16  0.014109\n",
       "2018-04-17  0.007000\n",
       "2018-04-18  0.000189\n",
       "2018-04-19 -0.003949\n",
       "2018-04-20 -0.007580\n",
       "2018-04-23  0.005786\n",
       "2018-04-24  0.004979\n",
       "2018-04-25  0.002551\n",
       "2018-04-26 -0.002409\n",
       "2018-04-27  0.000698\n",
       "2018-04-30  0.005172\n",
       "2018-05-01 -0.002832\n",
       "2018-05-02 -0.003971\n",
       "2018-05-03 -0.009396\n",
       "2018-05-04 -0.003759\n",
       "2018-05-07  0.004395\n",
       "2018-05-08  0.000182\n",
       "2018-05-09 -0.005701\n",
       "2018-05-10  0.001512\n",
       "2018-05-11  0.009115\n",
       "2018-05-14  0.003312\n",
       "2018-05-15 -0.007251\n",
       "2018-05-16 -0.001162\n",
       "2018-05-17 -0.002742\n",
       "2018-05-18 -0.002042\n",
       "\n",
       "[1237 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.Port_Wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 467)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.index = list(po.stock_data.index)[-1237:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-21</th>\n",
       "      <td>1.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-24</th>\n",
       "      <td>0.991485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-25</th>\n",
       "      <td>0.994853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-26</th>\n",
       "      <td>1.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-27</th>\n",
       "      <td>1.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-28</th>\n",
       "      <td>1.008295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>1.013515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>1.005849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>1.007337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>1.015402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-08</th>\n",
       "      <td>1.027044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-09</th>\n",
       "      <td>1.026373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-10</th>\n",
       "      <td>1.027046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-11</th>\n",
       "      <td>1.037590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-12</th>\n",
       "      <td>1.040419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-15</th>\n",
       "      <td>1.044318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-16</th>\n",
       "      <td>1.041713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-17</th>\n",
       "      <td>1.042111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-18</th>\n",
       "      <td>1.044661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-19</th>\n",
       "      <td>1.040939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-22</th>\n",
       "      <td>1.044611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-23</th>\n",
       "      <td>1.049789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>1.043846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>1.055073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-26</th>\n",
       "      <td>1.051154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>1.048070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-30</th>\n",
       "      <td>1.048906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>1.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>1.063336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-02</th>\n",
       "      <td>1.064319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>1.800360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>1.806424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>1.806104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>1.802618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13</th>\n",
       "      <td>1.802355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>1.827784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>1.840579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>1.840927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>1.833656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>1.819757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>1.830287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>1.839400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>1.844091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>1.839649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>1.840932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>1.850453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>1.845213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>1.837885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>1.820617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>1.813773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>1.821744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>1.822076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>1.814428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>1.830966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>1.837029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>1.823710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>1.821590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>1.816596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>1.812887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "2013-06-21  1.000562\n",
       "2013-06-24  0.991485\n",
       "2013-06-25  0.994853\n",
       "2013-06-26  1.000008\n",
       "2013-06-27  1.003675\n",
       "2013-06-28  1.008295\n",
       "2013-07-01  1.013515\n",
       "2013-07-02  1.005849\n",
       "2013-07-03  1.007337\n",
       "2013-07-05  1.015402\n",
       "2013-07-08  1.027044\n",
       "2013-07-09  1.026373\n",
       "2013-07-10  1.027046\n",
       "2013-07-11  1.037590\n",
       "2013-07-12  1.040419\n",
       "2013-07-15  1.044318\n",
       "2013-07-16  1.041713\n",
       "2013-07-17  1.042111\n",
       "2013-07-18  1.044661\n",
       "2013-07-19  1.040939\n",
       "2013-07-22  1.044611\n",
       "2013-07-23  1.049789\n",
       "2013-07-24  1.043846\n",
       "2013-07-25  1.055073\n",
       "2013-07-26  1.051154\n",
       "2013-07-29  1.048070\n",
       "2013-07-30  1.048906\n",
       "2013-07-31  1.050002\n",
       "2013-08-01  1.063336\n",
       "2013-08-02  1.064319\n",
       "...              ...\n",
       "2018-04-09  1.800360\n",
       "2018-04-10  1.806424\n",
       "2018-04-11  1.806104\n",
       "2018-04-12  1.802618\n",
       "2018-04-13  1.802355\n",
       "2018-04-16  1.827784\n",
       "2018-04-17  1.840579\n",
       "2018-04-18  1.840927\n",
       "2018-04-19  1.833656\n",
       "2018-04-20  1.819757\n",
       "2018-04-23  1.830287\n",
       "2018-04-24  1.839400\n",
       "2018-04-25  1.844091\n",
       "2018-04-26  1.839649\n",
       "2018-04-27  1.840932\n",
       "2018-04-30  1.850453\n",
       "2018-05-01  1.845213\n",
       "2018-05-02  1.837885\n",
       "2018-05-03  1.820617\n",
       "2018-05-04  1.813773\n",
       "2018-05-07  1.821744\n",
       "2018-05-08  1.822076\n",
       "2018-05-09  1.811688\n",
       "2018-05-10  1.814428\n",
       "2018-05-11  1.830966\n",
       "2018-05-14  1.837029\n",
       "2018-05-15  1.823710\n",
       "2018-05-16  1.821590\n",
       "2018-05-17  1.816596\n",
       "2018-05-18  1.812887\n",
       "\n",
       "[1237 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.007564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.003563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.001930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.003949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.007580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.009396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.005701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.007251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.001162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.002042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.000562\n",
       "1  -0.009072\n",
       "2   0.003396\n",
       "3   0.005182\n",
       "4   0.003667\n",
       "5   0.004603\n",
       "6   0.005177\n",
       "7  -0.007564\n",
       "8   0.001480\n",
       "9   0.008006\n",
       "10  0.011465\n",
       "11 -0.000653\n",
       "12  0.000656\n",
       "13  0.010266\n",
       "14  0.002726\n",
       "15  0.003748\n",
       "16 -0.002495\n",
       "17  0.000382\n",
       "18  0.002447\n",
       "19 -0.003563\n",
       "20  0.003528\n",
       "0   0.004957\n",
       "1  -0.005660\n",
       "2   0.010755\n",
       "3  -0.003715\n",
       "4  -0.002933\n",
       "5   0.000797\n",
       "6   0.001045\n",
       "7   0.012699\n",
       "8   0.000925\n",
       "..       ...\n",
       "10 -0.001053\n",
       "11  0.003369\n",
       "12 -0.000177\n",
       "13 -0.001930\n",
       "14 -0.000146\n",
       "15  0.014109\n",
       "16  0.007000\n",
       "17  0.000189\n",
       "18 -0.003949\n",
       "19 -0.007580\n",
       "20  0.005786\n",
       "0   0.004979\n",
       "1   0.002551\n",
       "2  -0.002409\n",
       "3   0.000698\n",
       "4   0.005172\n",
       "5  -0.002832\n",
       "6  -0.003971\n",
       "7  -0.009396\n",
       "8  -0.003759\n",
       "9   0.004395\n",
       "10  0.000182\n",
       "11 -0.005701\n",
       "12  0.001512\n",
       "13  0.009115\n",
       "14  0.003312\n",
       "15 -0.007251\n",
       "16 -0.001162\n",
       "17 -0.002742\n",
       "18 -0.002042\n",
       "\n",
       "[1237 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po.Realized_Return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
